2025-11-01 17:59:27,238 - main - INFO - ğŸš€ Initializing System Design RAG...
2025-11-01 17:59:27,238 - rag_pipeline - INFO - ğŸ”§ Initializing SystemDesignRAG...
2025-11-01 17:59:27,238 - models.llm - INFO - ğŸ¤– Initializing OllamaLLM with model: llama2
2025-11-01 17:59:27,262 - models.llm - INFO - âœ… Ollama client created successfully
2025-11-01 17:59:27,263 - models.llm - INFO - â„¹ï¸  No OpenAI API key found, will rely on Ollama only
2025-11-01 17:59:27,263 - rag_pipeline - INFO - ğŸ§  LLM initialized with model: llama2
2025-11-01 17:59:27,263 - rag_pipeline - INFO - âœ… SystemDesignRAG initialization complete!
2025-11-01 17:59:27,263 - main - INFO - âœ… System Design RAG initialized successfully!
2025-11-01 17:59:37,030 - main - INFO - ğŸš€ Initializing System Design RAG...
2025-11-01 17:59:37,031 - rag_pipeline - INFO - ğŸ”§ Initializing SystemDesignRAG...
2025-11-01 17:59:37,031 - models.llm - INFO - ğŸ¤– Initializing OllamaLLM with model: llama2
2025-11-01 17:59:37,054 - models.llm - INFO - âœ… Ollama client created successfully
2025-11-01 17:59:37,054 - models.llm - INFO - â„¹ï¸  No OpenAI API key found, will rely on Ollama only
2025-11-01 17:59:37,054 - rag_pipeline - INFO - ğŸ§  LLM initialized with model: llama2
2025-11-01 17:59:37,054 - rag_pipeline - INFO - âœ… SystemDesignRAG initialization complete!
2025-11-01 17:59:37,054 - main - INFO - âœ… System Design RAG initialized successfully!
2025-11-01 17:59:56,857 - main - INFO - ğŸ“¨ Received design request: 'Design a small scale url shortner...'
2025-11-01 17:59:56,857 - main - INFO - ğŸ”„ Processing request with RAG pipeline...
2025-11-01 17:59:56,857 - rag_pipeline - INFO - ğŸ¯ Starting generation for question: 'Design a small scale url shortner...'
2025-11-01 17:59:56,857 - rag_pipeline - INFO - ğŸ“ Enhanced prompt created, sending to LLM...
2025-11-01 17:59:56,857 - rag_pipeline - INFO - ğŸ“ Prompt length: 411 characters
2025-11-01 17:59:56,857 - models.llm - INFO - ğŸš€ Starting LLM generation...
2025-11-01 17:59:56,857 - models.llm - INFO - ğŸ” Checking Ollama availability...
2025-11-01 17:59:56,857 - models.llm - INFO - ğŸ” Checking if Ollama is available...
2025-11-01 17:59:56,857 - models.llm - INFO - ğŸ“‹ Fetching list of available models from Ollama...
2025-11-01 17:59:56,863 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-11-01 17:59:56,863 - models.llm - INFO - ğŸ“ Available models: ['llama2:latest']
2025-11-01 17:59:56,863 - models.llm - INFO - âœ… Model 'llama2' is available in Ollama
2025-11-01 17:59:56,863 - models.llm - INFO - âœ… Ollama is available, attempting generation...
2025-11-01 17:59:56,863 - models.llm - INFO - ğŸ“‹ Added system prompt to messages
2025-11-01 17:59:56,863 - models.llm - INFO - ğŸ’¬ Prepared 2 messages for Ollama
2025-11-01 17:59:56,863 - models.llm - INFO - ğŸ¯ Calling Ollama with model: llama2
2025-11-01 18:01:01,698 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-01 18:01:01,703 - models.llm - INFO - ğŸ‰ Ollama responded in 64.84 seconds
2025-11-01 18:01:01,703 - models.llm - INFO - ğŸ“ Response content length: 5376 characters
2025-11-01 18:01:01,703 - rag_pipeline - INFO - ğŸ‰ LLM response received in 64.85 seconds
2025-11-01 18:01:01,703 - rag_pipeline - INFO - ğŸ“Š Response length: 5376 characters
2025-11-01 18:01:01,703 - rag_pipeline - INFO - ğŸ” Response preview: 'System Design Solution for a Small Scale URL Shortener
=============================================...'
2025-11-01 18:01:01,703 - main - INFO - âœ… Request processed successfully in 64.85 seconds
2025-11-01 18:01:01,703 - main - INFO - ğŸ“¤ Response length: 5376 characters
2025-11-01 18:05:38,366 - main - INFO - ğŸ“¨ Received design request: 'Design a rate limiter. This is to prepare for a system design interview. How should I approach the p...'
2025-11-01 18:05:38,366 - main - INFO - ğŸ”„ Processing request with RAG pipeline...
2025-11-01 18:05:38,366 - rag_pipeline - INFO - ğŸ¯ Starting generation for question: 'Design a rate limiter. This is to prepare for a sy...'
2025-11-01 18:05:38,367 - rag_pipeline - INFO - ğŸ“ Enhanced prompt created, sending to LLM...
2025-11-01 18:05:38,367 - rag_pipeline - INFO - ğŸ“ Prompt length: 567 characters
2025-11-01 18:05:38,367 - models.llm - INFO - ğŸš€ Starting LLM generation...
2025-11-01 18:05:38,367 - models.llm - INFO - ğŸ” Checking Ollama availability...
2025-11-01 18:05:38,367 - models.llm - INFO - ğŸ” Checking if Ollama is available...
2025-11-01 18:05:38,367 - models.llm - INFO - ğŸ“‹ Fetching list of available models from Ollama...
2025-11-01 18:05:38,373 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-11-01 18:05:38,375 - models.llm - INFO - ğŸ“ Available models: ['llama2:latest']
2025-11-01 18:05:38,375 - models.llm - INFO - âœ… Model 'llama2' is available in Ollama
2025-11-01 18:05:38,375 - models.llm - INFO - âœ… Ollama is available, attempting generation...
2025-11-01 18:05:38,376 - models.llm - INFO - ğŸ“‹ Added system prompt to messages
2025-11-01 18:05:38,376 - models.llm - INFO - ğŸ’¬ Prepared 2 messages for Ollama
2025-11-01 18:05:38,376 - models.llm - INFO - ğŸ¯ Calling Ollama with model: llama2
2025-11-01 18:06:24,259 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-01 18:06:24,262 - models.llm - INFO - ğŸ‰ Ollama responded in 45.89 seconds
2025-11-01 18:06:24,262 - models.llm - INFO - ğŸ“ Response content length: 3671 characters
2025-11-01 18:06:24,262 - rag_pipeline - INFO - ğŸ‰ LLM response received in 45.90 seconds
2025-11-01 18:06:24,263 - rag_pipeline - INFO - ğŸ“Š Response length: 3671 characters
2025-11-01 18:06:24,263 - rag_pipeline - INFO - ğŸ” Response preview: ' System Design Solution for a Rate limiter:

### High-level Architecture Diagram

The high-level arc...'
2025-11-01 18:06:24,263 - main - INFO - âœ… Request processed successfully in 45.90 seconds
2025-11-01 18:06:24,263 - main - INFO - ğŸ“¤ Response length: 3671 characters
2025-11-01 18:09:58,793 - main - INFO - ğŸ“¨ Received design request: 'Hello, how are you?...'
2025-11-01 18:09:58,794 - main - INFO - ğŸ”„ Processing request with RAG pipeline...
2025-11-01 18:09:58,794 - rag_pipeline - INFO - ğŸ¯ Starting generation for question: 'Hello, how are you?...'
2025-11-01 18:09:58,794 - rag_pipeline - INFO - ğŸ“ Enhanced prompt created, sending to LLM...
2025-11-01 18:09:58,794 - rag_pipeline - INFO - ğŸ“ Prompt length: 397 characters
2025-11-01 18:09:58,794 - models.llm - INFO - ğŸš€ Starting LLM generation...
2025-11-01 18:09:58,794 - models.llm - INFO - ğŸ” Checking Ollama availability...
2025-11-01 18:09:58,794 - models.llm - INFO - ğŸ” Checking if Ollama is available...
2025-11-01 18:09:58,794 - models.llm - INFO - ğŸ“‹ Fetching list of available models from Ollama...
2025-11-01 18:09:58,800 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-11-01 18:09:58,800 - models.llm - INFO - ğŸ“ Available models: ['llama2:latest']
2025-11-01 18:09:58,800 - models.llm - INFO - âœ… Model 'llama2' is available in Ollama
2025-11-01 18:09:58,800 - models.llm - INFO - âœ… Ollama is available, attempting generation...
2025-11-01 18:09:58,800 - models.llm - INFO - ğŸ“‹ Added system prompt to messages
2025-11-01 18:09:58,800 - models.llm - INFO - ğŸ’¬ Prepared 2 messages for Ollama
2025-11-01 18:09:58,800 - models.llm - INFO - ğŸ¯ Calling Ollama with model: llama2
2025-11-01 18:11:20,547 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2025-11-01 18:11:20,553 - models.llm - INFO - ğŸ‰ Ollama responded in 81.75 seconds
2025-11-01 18:11:20,553 - models.llm - INFO - ğŸ“ Response content length: 6294 characters
2025-11-01 18:11:20,553 - rag_pipeline - INFO - ğŸ‰ LLM response received in 81.76 seconds
2025-11-01 18:11:20,553 - rag_pipeline - INFO - ğŸ“Š Response length: 6294 characters
2025-11-01 18:11:20,553 - rag_pipeline - INFO - ğŸ” Response preview: 'System Design Solution for "Hello, how are you?" Chatbot
===========================================...'
2025-11-01 18:11:20,553 - main - INFO - âœ… Request processed successfully in 81.76 seconds
2025-11-01 18:11:20,553 - main - INFO - ğŸ“¤ Response length: 6294 characters
